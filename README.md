[한국어](./README.ko.md) | [日本語](./README.ja.md) | [中文](./README.zh.md)

# Summary Bot

> A NestJS application that automatically summarizes URLs or text sent via a Telegram bot using an LLM, and saves the result as a markdown file to a GitHub repository

## Key Features

- **URL Content Extraction**: Send a web page URL and the bot automatically extracts the body text and summarizes it
- **X (Twitter) Tweet Support**: Automatically detects shared links within tweets and extracts the original content for summarization
- **Text Summarization**: Plain text (non-URL) can also be summarized
- **Dual LLM Providers**: Supports both Claude and Gemini with automatic fallback if the primary provider fails
- **Auto-save to GitHub**: Automatically commits summary results as markdown files to a GitHub repository
- **Knowledge Graph Structure**: Classifies upper/lower/related concepts alongside summaries to support knowledge map construction

## Architecture

```
Telegram → TelegramUpdate (Handler)
               ↓
         SummaryService (Orchestrator)
          ↓         ↓          ↓
  ExtractorService  LlmService  GithubService
                    ↓      ↓
            ClaudeProvider  GeminiProvider
```

### Module Overview

| Module | Role |
|------|------|
| `TelegramModule` | Receives Telegram webhooks and handles user interactions |
| `SummaryModule` | Orchestrates the summarization pipeline and manages cache |
| `ExtractorModule` | Extracts content from URLs (article-extractor, raw fetch, oEmbed) |
| `LlmModule` | Manages LLM providers and fallback logic |
| `GithubModule` | Generates markdown and saves files via the GitHub API |
| `HealthModule` | Health check endpoint (`GET /health`) |

## Processing Flow

1. The user sends a URL or text to the Telegram bot
2. `ExtractorService` analyzes the input:
   - **If URL**: Extracts the web page body (tries article-extractor → raw fetch → oEmbed in order)
   - **If X/Twitter URL**: Resolves the link within the tweet via the fxtwitter API, then extracts the body of the target URL
   - **If text**: Uses the original text as-is
3. `LlmService` summarizes the extracted content via LLM:
   - Generates a Korean title, English slug, category, tags, keywords, concept classification, insights, and a markdown summary
4. `GithubService` converts the summary result into a markdown file and auto-commits it to GitHub
5. Sends a summary preview and GitHub link back to Telegram
6. The user can press the `Delete` button to remove the cache, or the `Retry` button on error to re-summarize

## Summary Result Structure

The summary result generated by the LLM includes the following fields. Note that `title`, `keywords`, `concepts`, and `insights` are generated in Korean by the LLM.

| Field | Description |
|------|------|
| `title` | Korean title (up to 15 characters) |
| `description` | English kebab-case slug (used as filename) |
| `category` | One of `Tech` / `AI` / `Business` / `Design` / `Productivity` / `Life` |
| `tags` | 3-5 English tags |
| `keywords` | 3-7 Korean core keywords |
| `concepts.upper` | 1-3 upper-level concepts |
| `concepts.lower` | 2-5 lower/detailed concepts |
| `concepts.related` | 2-5 related concepts |
| `insights` | 3-5 key insights (declarative sentences) |
| `summary` | Detailed summary in markdown format |

## GitHub Save Format

Save path: `{SUMMARY_DIR}/YYYY-MM-DD-{slug}.md`

```markdown
---
title: "리액트 서버 컴포넌트의 이해"
date: 2025-02-10
category: Tech
tags: [react, server-components, nextjs]
keywords: [서버 컴포넌트, 클라이언트 컴포넌트, 번들 사이즈]
source: "https://example.com/article"
---

> 원문: https://example.com/article

## 요약 본문 ...

## 핵심 인사이트

- 인사이트 1
- 인사이트 2

## 키워드

`서버 컴포넌트` `클라이언트 컴포넌트` `번들 사이즈`

## 관련 개념

- **상위**: 웹 프레임워크, React 아키텍처
- **하위**: use client 지시어, 서버 전용 코드
- **연관**: 하이드레이션, Islands Architecture

> Auto-generated by Summary Bot on 2025-02-10
```

## Tech Stack

- **Runtime**: Node.js 20
- **Framework**: NestJS 11
- **Language**: TypeScript 5.7
- **Telegram**: Telegraf + nestjs-telegraf (Webhook mode)
- **LLM**: Anthropic Claude (`claude-sonnet-4-20250514`) / Google Gemini (`gemini-2.5-pro`)
- **GitHub**: Octokit REST API
- **Content Extraction**: @extractus/article-extractor
- **Package Manager**: pnpm 9.15
- **Deployment**: Docker (Multi-stage build)

## Getting Started

### Prerequisites

- Node.js 20+
- pnpm 9.15+
- Telegram Bot Token (create one via [BotFather](https://t.me/BotFather))
- LLM API Key (at least one of Anthropic or Google AI)
- GitHub Personal Access Token (with repo scope)

### Installation

```bash
# Clone the repository
git clone <repository-url>
cd summary-bot

# Install dependencies
pnpm install
```

### Environment Variables

Copy `.env.example` to `.env` and fill in the values:

```bash
cp .env.example .env
```

| Variable | Required | Description | Default |
|---------|------|------|--------|
| `TELEGRAM_BOT_TOKEN` | Yes | Telegram Bot API token | - |
| `TELEGRAM_WEBHOOK_DOMAIN` | Yes | Domain to receive webhooks (e.g., `https://example.com`) | - |
| `ANTHROPIC_API_KEY` | Cond. | Anthropic API key (required when using Claude) | - |
| `GEMINI_API_KEY` | Cond. | Google AI API key (required when using Gemini) | - |
| `GITHUB_TOKEN` | Yes | GitHub Personal Access Token | - |
| `GITHUB_REPO` | Yes | GitHub repository to save summaries (e.g., `owner/repo`) | - |
| `SUMMARY_DIR` | No | Directory for summary files within the repository | `98-summaries` |
| `LLM_PROVIDER` | No | Primary LLM provider (`claude` or `gemini`) | `gemini` |
| `PORT` | No | Server port | `3000` |

> The API key for the selected primary provider is required. It is recommended to set both keys to enable fallback.

### Development Mode

```bash
# Development server (auto-restart on file changes)
pnpm start:dev

# Debug mode
pnpm start:debug
```

### Production Build and Run

```bash
# Build
pnpm build

# Run in production
pnpm start:prod
```

### Running with Docker

```bash
# Build the image
docker build -t summary-bot .

# Run the container
docker run -d \
  --name summary-bot \
  -p 3000:3000 \
  --env-file .env \
  summary-bot
```

### Webhook Setup

Once the bot is running, you need to register the webhook URL with Telegram:

```
https://{TELEGRAM_WEBHOOK_DOMAIN}/api/telegram-webhook
```

`nestjs-telegraf` automatically sets up the webhook when the app starts. Set `TELEGRAM_WEBHOOK_DOMAIN` to a publicly accessible domain.

For local development, you can use a tunneling tool such as [ngrok](https://ngrok.com/):

```bash
ngrok http 3000
# Set the outputted HTTPS URL as TELEGRAM_WEBHOOK_DOMAIN
```

## Usage

1. Send a URL or text as a DM to the bot on Telegram.
2. The bot displays a "Summarizing..." status while processing the content.
3. Once the summary is complete, a preview message is sent containing:
   - Title and category/tags
   - Summary preview (300 characters)
   - Key insights
   - Keywords
   - GitHub link
4. Press the `Delete` button to remove from cache and delete the message.
5. If an error occurs, press the `Retry` button to re-attempt summarization.

## Scripts

| Command | Description |
|--------|------|
| `pnpm start:dev` | Run development server (watch mode) |
| `pnpm start:debug` | Run in debug mode |
| `pnpm build` | Production build |
| `pnpm start:prod` | Run in production |
| `pnpm lint` | Run ESLint |
| `pnpm format` | Run Prettier formatting |

## Project Structure

```
src/
├── main.ts                      # NestJS bootstrap and webhook setup
├── app.module.ts                # Root module
├── config/
│   └── configuration.ts         # Environment variable configuration
├── telegram/
│   ├── telegram.module.ts       # Telegram module (webhook setup)
│   └── telegram.update.ts       # Message handler and inline button handling
├── summary/
│   ├── summary.module.ts        # Summary module
│   └── summary.service.ts       # Summary pipeline orchestration
├── extractor/
│   ├── extractor.module.ts      # Extractor module
│   └── extractor.service.ts     # URL/text content extraction
├── llm/
│   ├── llm.module.ts            # LLM module
│   ├── llm.service.ts           # LLM service (fallback logic)
│   ├── llm.interface.ts         # SummaryResult interface
│   ├── prompts.ts               # LLM system/user prompts
│   └── providers/
│       ├── claude.provider.ts   # Anthropic Claude provider
│       └── gemini.provider.ts   # Google Gemini provider
├── github/
│   ├── github.module.ts         # GitHub module
│   └── github.service.ts        # GitHub markdown storage
└── health/
    ├── health.module.ts         # Health module
    └── health.controller.ts     # GET /health endpoint
```

## License

MIT
